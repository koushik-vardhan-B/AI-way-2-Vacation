2025-10-26 22:25:23 - api.dependencies - ERROR - Failed to create GraphBuilder: 'PlaceSearchTool' object has no attribute 'get_tools'
2025-10-26 22:27:08 - api.dependencies - ERROR - Failed to create GraphBuilder: 'PlaceSearchTool' object has no attribute 'get_tools'
2025-10-26 22:39:51 - api.dependencies - ERROR - Failed to create GraphBuilder: 'PlaceSearchTool' object has no attribute 'get_tools'
2025-10-26 22:43:50 - api.dependencies - ERROR - Failed to create GraphBuilder: GraphBuilder() takes no arguments
2025-10-26 22:46:20 - api.dependencies - ERROR - Failed to create GraphBuilder: GraphBuilder() takes no arguments
2025-10-26 22:50:18 - api.routes.plans_routes - ERROR - ‚ùå Error in conversation for plan 2: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jt56vxpmfaqr765ngjnwbtvh` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 98075, Requested 6442. Please try again in 1h5m2.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/api/routes/plans_routes.py", line 190, in continue_conversation
    output = react_app.invoke({"messages": langgraph_messages}, config)
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langgraph/pregel/main.py", line 3085, in invoke
    for chunk in self.stream(
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langgraph/pregel/main.py", line 2674, in stream
    for _ in runner.tick(
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langgraph/pregel/_runner.py", line 162, in tick
    run_with_retry(
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langgraph/pregel/_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langgraph/_internal/_runnable.py", line 657, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langgraph/_internal/_runnable.py", line 401, in invoke
    ret = self.func(*args, **kwargs)
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/agent/agentic_workflow.py", line 70, in agent_function
    response = self.llm_with_tools.invoke(input_question)
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langchain_core/runnables/base.py", line 5711, in invoke
    return self.bound.invoke(
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 395, in invoke
    self.generate_prompt(
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 1025, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 842, in generate
    self._generate_with_cache(
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 1091, in _generate_with_cache
    result = self._generate(
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/langchain_groq/chat_models.py", line 533, in _generate
    response = self.client.create(messages=message_dicts, **params)
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/home/koushikvardhan/Music/Way-2-Vacation-main/venv/lib/python3.10/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jt56vxpmfaqr765ngjnwbtvh` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 98075, Requested 6442. Please try again in 1h5m2.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
